---
layout: archive_pub
title: "Publications"
permalink: /publications_type/
author_profile: true
redirect_from:
- /resume
---
{% include base_path %}
### [Sort publications by date](/publications_year)

## Journal
<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-3DOR-conv.png"> 

<div class="archive__column_text"><small>
<b>ConvPoint: Continuous Convolutions for Point Cloud Processing</b><br/>in Computers & Graphics, 2020<br/><i>A. Boulch</i><br/><a href="https://www.sciencedirect.com/science/article/abs/pii/S0097849320300224">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1904.02375">Arxiv</a>&nbsp;&nbsp;<a href="https://github.com/aboulch/ConvPoint">Code</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-CVIU-distance.png"> 

<div class="archive__column_text"><small>
<b>Distance transform regression for spatially-aware deep semantic segmentation</b><br/>in Computer Vision and Image Understanding (CVIU), 2019<br/><i>N. Audebert, A. Boulch, B. Le Saux and S. Lefèvre</i><br/><a href="https://www.sciencedirect.com/science/article/pii/S1077314219301201">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1909.01671">Arxiv</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2018-CVIU-change.png"> 

<div class="archive__column_text"><small>
<b>High Resolution Semantic Change Detection</b><br/>in Computer Vision and Image Understanding (CVIU), 2019<br/><i>R. C. Daudt, B. Le Saux, A. Boulch, Y. Gousseau</i><br/><a href="https://www.sciencedirect.com/science/article/pii/S1077314219300992">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1810.08452">Arxiv</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2018-PRL-sharesnet.png"> 

<div class="archive__column_text"><small>
<b>ShaResNet: reducing residual network parameter number by sharing weights</b><br/>in Pattern Recognition Letters, 2018<br/><i>A.Boulch</i><br/><a href="https://www.sciencedirect.com/science/article/pii/S0167865518300060">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1702.08782">Arxiv</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-CAG-snapnet.png "> 

<div class="archive__column_text"><small>
<b>SnapNet: Unstructured point cloud semantic labeling using deep segmentation networks</b><br/>in Computer and Graphics, 2018<br/>also in Eurographics Workshop 3D Object Retrieval 2017<br/><i>A. Boulch, J. Guerry, B. Le Saux and N. Audebert</i><br/><a href="https://www.sciencedirect.com/science/article/pii/S0097849317301942">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2017_cag_snapNet.pdf">PDF</a>&nbsp;&nbsp;<a href="https://github.com/aboulch/snapnet">Code</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2016-JSTARS-eo.png"> 

<div class="archive__column_text"><small>
<b>Benchmarking classification of earth-observation data: from learning explicit features to convolutional networks</b><br/>in IEEE JSTARS, 2016<br/>also in IGARSS 2015<br/><span style="color:red">Awarded paper of the 2015 IEEE GRSS Data Fusion Contest</span><br/><i>A. Lagrange, B. Le Saux, A. Beaupere, A. Boulch, A. Chan-Hon-Tong, S. Herbin, H. Randrianarivo and M. Ferecatu</i><br/><a href="https://ieeexplore.ieee.org/document/7326745">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2015_DFC_classif_benchmark.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2014-CGF-recons.png"> 

<div class="archive__column_text"><small>
<b>Piecewise-Planar 3D Reconstruction with Edge and Corner Regularization</b><br/>in Computer Graphics Forum, Wiley, 2014<br/>also in Symposium on Geometry Processing 2014 (SGP 2014)<br/><i>A. Boulch, M. De La Gorce and R. Marlet</i><br/><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12431">Paper</a>&nbsp;&nbsp;<a href="https://hal.archives-ouvertes.fr/hal-01099280/document">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2013-CGF-grammars.png"> 

<div class="archive__column_text"><small>
<b>Semantizing Complex 3D Scenes using Constrained Attribute Grammars</b><br/>in Computer Graphics Forum, Wiley, 2013<br/>also in Symposium on Geometry Processing 2013 (SGP 2013)<br/><i>A. Boulch, S. Houllier, R. Marlet and O. Tournaire</i><br/><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12170">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2013_sgp_boulch.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2012-GaC-triangulation.png"> 

<div class="archive__column_text"><small>
<b>Irreducible Triangulations of Surfaces with Boundary</b><br/>in Graphs and Combinatorics, Springer Verlag, 2012<br/><i>A. Boulch, É. Colin de Verdière and A. Nakamoto</i><br/><a href="https://link.springer.com/article/10.1007/s00373-012-1244-1">Paper</a>&nbsp;&nbsp;<a href="https://hal.archives-ouvertes.fr/hal-01163747/document">HAL</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2012-CGF-normals.png"> 

<div class="archive__column_text"><small>
<b>Fast Normal Estimation for Point Clouds with Sharp Features using a Robust Randomized Hough Transform</b><br/>in Computer Graphics Forum, Wiley, 2012<br/>also in Symposium on Geometry Processing 2012 (SGP 2012)<br/><i>A. Boulch and R. Marlet</i><br/><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2012.03181.x">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2012_sgp_boulch.pdf">PDF</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/talks/2012_sgp_boulch_slides.pdf">Slides</a>&nbsp;&nbsp;<a href="https://github.com/aboulch/normals_Hough">Code</a>&nbsp;&nbsp;</small></div></div>

## Conference
<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2020-ECCV-FLOT.png"> 

<div class="archive__column_text"><small>
<b>FLOT: Scene Flow on Point Clouds Guided by Optimal Transport</b><br/>in European Conference on Computer Vision (ECCV), 2020<br/><i>G. Puy, A. Boulch and R. Marlet</i><br/><a href="https://arxiv.org/abs/2007.11142">Arxiv</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-JURSE-semi.png"> 

<div class="archive__column_text"><small>
<b>What data do we need for semantic segmentation in Earth-observation?</b><br/>in IEEE Joint Urban Remote Sensing Event (JURSE’2019), 2019<br/><i>J. Castillo Navarro, N. Audebert, A. Boulch, B. Le Saux, S. Lefèvre</i><br/><a href="https://ieeexplore.ieee.org/document/8809071">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2019_jurse_data.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-IGARSS-eo.png "> 

<div class="archive__column_text"><small>
<b>Learning to Understand Earth Observation Images with Weak and Unreliable Ground Truth</b><br/>in International Geoscience and Remote Sensing Symposium, IGARSS, 2019<br/><i>R. C. Daudt, A. Chan-Hon-Tong, B. Le Saux, A. Boulch</i><br/><a href="https://ieeexplore.ieee.org/document/8898563">Paper</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-CVPR-EarthVision-change.png"> 

<div class="archive__column_text"><small>
<b>Guided Anisotropic Diffusion and Iterative Learning for Weakly Supervised Change Detection</b><br/>in IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) workshop EarthVision 19, 2019<br/><span style="color:red">Best Student Paper Award: 1st place</span><br/><i>R. C. Daudt, B. Le Saux, A. Boulch, Y. Gousseau</i><br/><a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/EarthVision/Daudt_Guided_Anisotropic_Diffusion_and_Iterative_Learning_for_Weakly_Supervised_Change_CVPRW_2019_paper.pdf">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1904.08208">Arxiv</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-3DV-line.png"> 

<div class="archive__column_text"><small>
<b>Surface Reconstruction from 3D Line Segments</b><br/>in International Conference on 3D vision (3DV 2019), 2019<br/><i>P.-A. Langlois, A. Boulch, R. Marlet</i><br/><a href="https://ieeexplore.ieee.org/abstract/document/8885913">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1911.00451">Arxiv</a>&nbsp;&nbsp;<a href="https://hal.archives-ouvertes.fr/hal-02344362/">HAL</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-3DV-disparity.png"> 

<div class="archive__column_text"><small>
<b>Fast Stereo Disparity Maps Refinement By Fusion of Data-Based And Model-Based Estimations</b><br/>in International Conference on 3D vision (3DV 2019), 2019<br/><i>M. Ferrera, A. Boulch, J. Moras</i><br/><a href="https://ieeexplore.ieee.org/abstract/document/8886031">Paper</a>&nbsp;&nbsp;<a href="https://hal.archives-ouvertes.fr/hal-02326896/document">HAL</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-3DOR-conv.png "> 

<div class="archive__column_text"><small>
<b>Generalizing discrete convolutions for unstructured point clouds</b><br/>in Eurographics Workshop 3D Object Retrieval (3DOR), 2019<br/><i>A. Boulch</i><br/><a href="https://diglib.eg.org/handle/10.2312/3dor20191064">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1904.02375">Arxiv</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/talks/2019_3dor_conv_slides.pdf">Slides</a>&nbsp;&nbsp;<a href="https://github.com/aboulch/ConvPoint">Code</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2019-RFIAP-distance.png"> 

<div class="archive__column_text"><small>
<b>Segmentation semantique profonde par regression sur cartes de distances signees</b><br/>in Conference Reconnaissance des Formes, Images, Apprentissage et Perception, RFIAP, 2018<br/><i>N. Audebert, A. Boulch, B. Le Saux, S. Lefevre</i><br/><a href="ttps://hal.archives-ouvertes.fr/hal-01809991v1">HAL</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2018-ICIP-change.png"> 

<div class="archive__column_text"><small>
<b>Détection dense de changements par réseaux de neurones siamois</b><br/>in Conference Reconnaissance des Formes, Images, Apprentissage et Perception, RFIAP, 2018<br/><i>R. Caye Daudt, B. Le Saux, A. Boulch, Y. Gousseau</i><br/><a href="https://hal.archives-ouvertes.fr/hal-01823684">HAL</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2018-IGARSS-denoising.png"> 

<div class="archive__column_text"><small>
<b>Learning speckle suppression in SAR images without ground truth: application to Sentinel-1 time-series</b><br/>in International Geoscience and Remote Sensing Symposium, IGARSS, 2018<br/><i>A. Boulch, P. Trouve, E. Koeniguer, F. Janez, B. Le Saux</i><br/><a href="https://aboulch.github.io/files/2018_igarss_denoising-sentinel.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2018-IGARSS-change.png"> 

<div class="archive__column_text"><small>
<b>Urban Change Detection for Multispectral Earth Observation Using Convolutional Neural Networks</b><br/>in International Geoscience and Remote Sensing Symposium, IGARSS, 2018<br/><i>R. C. Daudt, B. Le Saux, A. Boulch, Y. Gousseau</i><br/><a href="https://ieeexplore.ieee.org/document/8518015">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1810.08468">Arxiv</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2018-ICIP-change.png"> 

<div class="archive__column_text"><small>
<b>Fully Convolutional Siamese Networks for Change Detection</b><br/>in IEEE International Conference on Image Processing, 2018<br/><i>R. Caye Daudt, B. Le Saux, A. Boulch</i><br/><a href="https://ieeexplore.ieee.org/document/8451652">Paper</a>&nbsp;&nbsp;<a href="https://arxiv.org/abs/1810.08462">Arxiv</a>&nbsp;&nbsp;<a href="https://hal.archives-ouvertes.fr/hal-01824557">HAL</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-JURSE-deep.png"> 

<div class="archive__column_text"><small>
<b>Deep Learning for Urban Remote Sensing</b><br/>in Joint Urban Remote Sensing Event, JURSE, 2017<br/><i>N. Audebert, A. Boulch, H. Randrianarivo, B. Le Saux, M. Ferecatu, S. Lefèvre and R. Marlet</i><br/><a href="https://ieeexplore.ieee.org/document/7924536">Paper</a>&nbsp;&nbsp;<a href="https://hal.archives-ouvertes.fr/hal-01672854">HAL</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2017_jurse_deep.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-ICONIP-space.png"> 

<div class="archive__column_text"><small>
<b>Deep sequence-to-sequence neural networks for ionospheric activity map prediction</b><br/>in ICONIP, 2017<br/><i>N. Cherrier, T. Castaings and A. Boulch</i><br/><a href="https://link.springer.com/chapter/10.1007/978-3-319-70139-4_55">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2017_iconip_spatial_forecasting.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-ICCV-3DRMS-snapnetR.png"> 

<div class="archive__column_text"><small>
<b>SnapNet-R: Consistent 3D Multi-View Semantic Labeling for Robotics</b><br/>in Workshop 3D Reconstruction Meets Semantics (3DRMS), ICCV, 2017<br/><i>J. Guerry, A. Boulch, B. Le Saux, J. Moras, A. Plyer and D. Filliat</i><br/><a href="https://ieeexplore.ieee.org/document/8265294">Paper</a>&nbsp;&nbsp;<a href="https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w13/Guerry_SnapNet-R_Consistent_3D_ICCV_2017_paper.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-GRETSI-ae.png"> 

<div class="archive__column_text"><small>
<b>Autoencodeurs pour la visualisation d\'images hyperspectrales</b><br/>in XXV colloque Gretsi, 2017<br/><i>A. Boulch, N. Audebert and D. Dubucq</i><br/><a href="https://aboulch.github.io/files/2017_gretsi-autoencodeurs.pdf">PDF</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/posters/2017_gretsi-autoencodeurs_poster.pdf">Poster</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-ICONIP-space.png"> 

<div class="archive__column_text"><small>
<b>Forecasting ionospheric Total Electron Content maps with deep neural networks</b><br/>in Big Data from Space (BIDS), ESA Workshop, 2017<br/><i>N. Cherrier, T. Castaings and A. Boulch</i><br/><a href="https://aboulch.github.io/files/2017_bids_esa_forecasting.pdf">PDF</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/talks/2017_bids_esa_forecasting_slides.pdf">Slides</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-BIDS-shelf.png"> 

<div class="archive__column_text"><small>
<b>Off the shelf deep learning pipeline for remote sensing applications</b><br/>in Big Data from Space (BIDS), ESA Workshop, 2017<br/><i>R. Tripathi, A. Chan-Hon-Tong and A. Boulch</i><br/><a href="https://aboulch.github.io/files/2017_bids_esa_shelf-dl.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-3DOR-SHREC-toys.png"> 

<div class="archive__column_text"><small>
<b>SHREC'17 Track: Point-Cloud Shape Retrieval of Non-Rigid Toys</b><br/>in 10th Eurographics workshop on 3D Object retrieval, 3DOR, 2017<br/><i>F. A. Limberger, W. C. Richard, M. Aono, N. Audebert, A. Boulch, B. Bustos, A. Giachetti, A. Godil, B. Le Saux and B. Li and others</i><br/><a href="https://diglib.eg.org/handle/10.2312/3dor20171056">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2017_3dor-shrec-toys.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-3DOR-SHREC-shapes.png"> 

<div class="archive__column_text"><small>
<b>SHREC’17: Deformable Shape Retrieval with Missing Parts</b><br/>in 10th Eurographics workshop on 3D Object retrieval, 3DOR, 2017<br/><i>E. Rodola, L. Cosmo, O. Litany, MM. Bronstein, AM. Bronstein, N. Audebert, A. Ben Hamza, A. Boulch, U. Castellani, MN. Do and others</i><br/><a href="https://diglib.eg.org/handle/10.2312/3dor20171057">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2017_3dor-shrec-shapes.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2016-ODAS-DL4RS.png"> 

<div class="archive__column_text"><small>
<b>Deep Learning for Remote Sensing</b><br/>in Onera-DLR Aerospace Symposium (ODAS), 2016<br/><i>N. Audebert, A. Boulch, A. Lagrange, B. Le Saux and S. Lefèvre</i><br/><a href="https://aboulch.github.io/files/2016_ODAS_DeepLearn4RemoteSensing.pdf">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2015-GRETSI-boxes.png"> 

<div class="archive__column_text"><small>
<b>Un générateur de boites englobantes parcimonieux pour la détection d'objets dans des vidéos</b><br/>in XXV colloque Gretsi, 2015<br/><i>A. Chan-Hon-Tong, S. Herbin and A. Boulch</i><br/><a href="https://hal.archives-ouvertes.fr/hal-01175556/document">PDF</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2014-ICPR-primitives.png"> 

<div class="archive__column_text"><small>
<b>Statistical Criteria for Shape Fusion and Selection</b><br/>in International Conference on Pattern Recognition, ICPR, 2014<br/><i>A. Boulch, R. Marlet</i><br/><a href="https://dl.acm.org/doi/abs/10.1109/ICPR.2014.171">Paper</a>&nbsp;&nbsp;<a href="https://aboulch.github.io/files/2014_icpr_boulch.pdf">PDF</a>&nbsp;&nbsp;<a href="https://github.com/aboulch/primitive_merging">Code</a>&nbsp;&nbsp;</small></div></div>

## Arxiv
<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2020-starflow.png"> 

<div class="archive__column_text"><small>
<b>STaRFlow: A SpatioTemporal Recurrent Cell for Lightweight Multi-Frame Optical Flow Estimation</b><br/>in Arxiv, 2020<br/><i>P.Godet, A. Boulch, A. Plyer and G. Le Besnerais</i><br/><a href="https://arxiv.org/abs/2007.05481">Arxiv</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2020-fkaconv.png"> 

<div class="archive__column_text"><small>
<b>FKAConv: Feature-Kernel Alignment for Point Cloud Convolution</b><br/>in Arxiv, 2020<br/><i>A. Boulch, G. Puy and R. Marlet</i><br/><a href="https://arxiv.org/abs/2004.04462">Arxiv</a>&nbsp;&nbsp;<a href="https://github.com/valeoai/LightConvPoint">Code</a>&nbsp;&nbsp;</small></div></div>

<div class="archive__row"><img align="left" style="padding-right: 10px; padding-top: 5px; padding-bottom: 5px" src="/images/publications/2017-ICONIP-space.png"> 

<div class="archive__column_text"><small>
<b>Ionospheric activity prediction using convolutional recurrent neural networks</b><br/>in Arxiv, 2018<br/><i>A. Boulch, N. Cherrier, T. Castaings</i><br/><a href="https://arxiv.org/abs/1810.13273">Arxiv</a>&nbsp;&nbsp;<a href="ttps://github.com/aboulch/tec_prediction">Code</a>&nbsp;&nbsp;</small></div></div>

