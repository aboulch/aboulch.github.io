---
layout: publication
title: "Deep Surface Reconstruction from Point Clouds with Visibility Information"
author: "R. Sulzer, L. Landrieu, A. Boulch, R. Marlet and B. Vallet"
permalink: /publications/2022_icpr_surface_visibility
date: 2022-08-01
venue: "International Conference on Pattern Recognition (ICPR)"
---

[Paper](https://ieeexplore.ieee.org/document/9956560){: .btn .btn-purple .mr-4 }
[Arxiv](https://arxiv.org/abs/2202.01810){: .btn .btn-purple .mr-4 }
[HAL](https://hal.archives-ouvertes.fr/hal-03575517/document){: .btn .btn-purple .mr-4 }
[Code](https://github.com/raphaelsulzer/dsrv-data){: .btn .btn-purple .mr-4 }

### Abstract

Most current neural networks for reconstructing surfaces from point clouds ignore sensor poses and only operate on raw point locations. Sensor visibility, however, holds meaningful information regarding space occupancy 
and surface orientation. In this paper, we present two simple ways to augment raw point clouds with visibility information, so it can directly be leveraged by surface reconstruction networks with minimal adaptation. 
Our proposed modifications consistently improve the accuracy of generated surfaces as well as the generalization ability of the networks to unseen shape domains. 