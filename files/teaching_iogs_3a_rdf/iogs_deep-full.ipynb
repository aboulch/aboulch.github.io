{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "my7Myevmy3G0"
   },
   "source": [
    "# IOGS - Machine learning and pattern recognition\n",
    "\n",
    "## Class objective\n",
    "\n",
    "The objective of this class is to build from scratch a convolutional neural network (CNN) using PyToch framework.\n",
    "\n",
    "To make the optimization efficient, will work with the GPU acceleration provided by Colab.\n",
    "To set the GPU acceleration:\n",
    "* Edit\n",
    "* Notebook settings\n",
    "* Hardware accelerator: **GPU**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_COLAB = False # define a variable, on colab or not (should be set to True on Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Package installation and imports\n",
    " \n",
    "As in the provious class, we need to install Pytorch (if it is already installed, it won't be a second time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "WgotTlOXT-kk",
    "outputId": "1736ac42-9dad-44d0-d44f-1d495f4285d5"
   },
   "outputs": [],
   "source": [
    "if USE_COLAB:\n",
    "    # download and install Pytorch\n",
    "    !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmigEWmAyzUj"
   },
   "source": [
    "We also need several inports from different libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxzVjTgYUYdW"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm # for progress bars\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch\n",
    "import torch # deep learning framework\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "We will use the CIFAR10 dataset for image classification. It is one of the most used classification dataset for first experiences.\n",
    "It is composed of 60000 images (50000 for training, 10000 for testing).\n",
    "\n",
    "### Defining the directory to store data\n",
    "\n",
    "When using Colab, the data is stored in the drive. The first thing to do is to mount the drive as a folder for the notebook.\n",
    "*note*: if not using Colab, we set the default download dir in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "q2DWIZdCUvbo",
    "outputId": "b240165c-60c9-4fa6-a4c5-01324cffdb92"
   },
   "outputs": [],
   "source": [
    "if USE_COLAB:\n",
    "    # mount the goole drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # download cifar on GoogleDrive\n",
    "    data_dir = \"/content/drive/My Drive/dataset/cifar\"\n",
    "else:\n",
    "    data_dir = \"./cifar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AX9Tb6wcBSPX"
   },
   "source": [
    "### Dataloaders\n",
    "\n",
    "PyTorch and TorchVision offer classes for an easy data usage.\n",
    "\n",
    "The Dataset class, allow to apply data transformation such as normalization or data augmentation.\n",
    "\n",
    "For the CIFAR10 dataset, a specific dataset class is coded.\n",
    "It will download the data if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "-KLKxMqjXLnx",
    "outputId": "22acf0ae-d004-46af-95ca-e1bbdfeaa5d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# transformations for images (convert to pytorch tensor and center data)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# create the train dataset and test dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are then used in dataloaders.\n",
    "The dataloaders are multithreaded and create the batches of data used for optimization at the given batch size.\n",
    "They can shuffle the data, if specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "-KLKxMqjXLnx",
    "outputId": "22acf0ae-d004-46af-95ca-e1bbdfeaa5d2"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# build dataset for cifar 10\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "\n",
    "CIFAR10 as 10 classes for classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition\n",
    "\n",
    "The state of the art for image classification is convolutional neural networks (CNN).\n",
    "These CNNs have become more and more complex and involve today a high number of convolutional layers.\n",
    "In this class to keep the optimization possible in the time of the class, we will use a very simple network based on LeNet-5.\n",
    "\n",
    "<font color='red'>Question</font> Create a network with 3 convolutions and 2 linear layers.\n",
    "\n",
    "The network will be:\n",
    "```\n",
    "conv (3 -> 16, kernel 3x3)\n",
    "relu \n",
    "max_pooling\n",
    "conv (16 -> 32, kernel 3x3)\n",
    "relu \n",
    "max_pooling\n",
    "conv (32 -> 64, kernel 3x3)\n",
    "relu \n",
    "max_pooling\n",
    "Linear (256 -> 128)\n",
    "relu\n",
    "Linear (128 -> 10)\n",
    "```\n",
    "In the ```__init__``` function, you need to declare the layers with parameters (convolutional and linear layers).\n",
    "In the ```forward``` function, you describe the information flow from the input (x) to the final output.\n",
    "\n",
    "The object with parameters are:\n",
    "* ```nn.Conv2d(a,b,c)``` where ```a``` is the input channel number, ```b``` the output channel number and ```c``` the kernel size.\n",
    "* ```nn.Linear(a,b)``` where ```a``` is the input size, ```b``` the output size\n",
    "\n",
    "Here are some useful functions:\n",
    "* ```F.relu(a)```: apply a relu on ```a```\n",
    "* ```F.max_pool2d(a,2)```: apply a max pooling of size 2 on ```a```\n",
    "* ```b = a.view(a.size(0), -1)```: flattens ```a``` to be usable with linear layer (shoud be used between 2d operations and 1d operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJ7PqoP4rPyJ"
   },
   "outputs": [],
   "source": [
    "# network class\n",
    "class SimpleCNN(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    \n",
    "    # define here the convolutions and linear layers\n",
    "    # self.conv1 = ....\n",
    "    self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "    self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "    self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "    self.fc1 = nn.Linear(64*2*2,128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    \n",
    "    # define here the forward pass\n",
    "    # x_cv1 = ...\n",
    "    \n",
    "    # convolution stage 1\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "\n",
    "    # convolution stage 2\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    \n",
    "    # convolution stage 3\n",
    "    x = F.relu(self.conv3(x))\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    \n",
    "    # fully convolutional part\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "In this practical session, we will only use the global accuracy, defined by the number of correctly classified elements over the total number of sample.\n",
    "\n",
    "<font color='red'>Question</font>: define the accuracy function, from a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cm):\n",
    "    # code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main optimization loop\n",
    "\n",
    "This is the main loop for optimization.\n",
    "It follows the same principles as the MLP of the previous class.\n",
    "\n",
    "#### Train\n",
    "\n",
    "<font color='red'>Question</font>: Set the gradients to zero\n",
    "<font color='red'>Question</font>: Compute the outputs\n",
    "<font color='red'>Question</font>: Compute the cross entropy loss\n",
    "<font color='red'>Question</font>: Call backward on the loss\n",
    "<font color='red'>Question</font>: Call step on the optimizer\n",
    "<font color='red'>Question</font>: Compute the predictions on the outputs (in numpy format), it is the argmax of the prediction vector\n",
    "<font color='red'>Question</font>: Update the confusion matrix\n",
    "\n",
    "#### Test\n",
    "<font color='red'>Question</font>: Compute the outputs\n",
    "<font color='red'>Question</font>: Compute the predictions on the outputs (in numpy format), it is the argmax of the prediction vector\n",
    "<font color='red'>Question</font>: Update the confusion matrix\n",
    "\n",
    "#### Display results\n",
    "<font color='red'>Question</font>: Compute train and test accuracies, display them\n",
    "<font color='red'>Question</font>: Save these accuracy in the corresponding lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "JB3GuOqn6OlQ",
    "outputId": "9ca15e62-5071-4634-acab-4a35854ee00b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2:   0%|                                         | 0/1563 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OA train 0.32328 | OA test 0.34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  41%|████████████▏                 | 637/1563 [00:05<00:08, 105.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7e2899f90f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create the network\n",
    "network = SimpleCNN()\n",
    "network.cuda()\n",
    "  \n",
    "# create an optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "max_epoch = 10\n",
    "\n",
    "# list for saving accuracies\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# iterate over epochs\n",
    "for epoch in range(max_epoch):\n",
    "    \n",
    "    # set the network in train mode\n",
    "    network.train()\n",
    "    \n",
    "    # create a zero confuction matrix\n",
    "    cm = np.zeros((10,10))\n",
    "    \n",
    "    for inputs, targets in tqdm(trainloader, ncols=80, desc=\"Epoch {}\".format(epoch)):\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        # gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute outputs\n",
    "        # outputs = ...\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        \n",
    "        # backward on loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # convert the torch tensors to numpy\n",
    "        outputs_np = outputs.cpu().detach().numpy()\n",
    "        targets_np = targets.cpu().detach().numpy()\n",
    "        \n",
    "        # compute the predictions\n",
    "        predictions = np.argmax(outputs_np, axis=1)\n",
    "        \n",
    "        # update the confusion matrix\n",
    "        cm += confusion_matrix(targets_np.ravel(), predictions.ravel(), labels=range(len(classes)))\n",
    "\n",
    "    # set the network to evaluatio mode\n",
    "    network.eval()\n",
    "    \n",
    "    # create the confusion matrix\n",
    "    cm_test = np.zeros((10,10))\n",
    "    # tell not to reserve memory space for gradients (much faster)\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(testloader, ncols=80, desc=\" Test {}\".format(epoch)):\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            # compute outputs\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            outputs_np = outputs.cpu().detach().numpy()\n",
    "            targets_np = targets.cpu().detach().numpy()\n",
    "            \n",
    "            # compute predictions\n",
    "            predictions = np.argmax(outputs_np, axis=1)\n",
    "            \n",
    "            # compute confusion matrix\n",
    "            cm_test += confusion_matrix(targets_np.ravel(), predictions.ravel(), labels=range(len(classes)))\n",
    "\n",
    "    clear_output()\n",
    "    oa_train = cm.diagonal().sum() / cm.sum()\n",
    "    oa_test = cm_test.diagonal().sum()/cm_test.sum()\n",
    "\n",
    "    print(\"\\n OA train {} | OA test {}\".format(oa_train, oa_test))\n",
    "    print(\"\")\n",
    "    \n",
    "    train_accs.append(oa_train)\n",
    "    test_accs.append(oa_test)\n",
    "\n",
    "print(\"Train accuracies\")\n",
    "print(train_accs)\n",
    "print(\"Test accuracies\")\n",
    "print(test_accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pHgoBPt2JVM"
   },
   "source": [
    "### Analysis\n",
    "\n",
    "<font color='red'>Question</font>: copy paste the accuracy list in new variables (to save the results)\n",
    "<font color='red'>Question</font>: display the training and testing curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GkhKBnp5Owp"
   },
   "outputs": [],
   "source": [
    "# display the curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "In this part, the objective is play with the network to improve the results.\n",
    "You can add more convolutional layers, batchnorm, train for longer...\n",
    "\n",
    "<font color='red'>Question</font>: each time you do a modification, save the results along with the previous results and display the curves.\n",
    "\n",
    "**Note**: the state of the art on this dataset is around 95% for the test. Reaching that is difficult and would require training for a long time, but you can try to get as close as possible !"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "iogs_cifar.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
