{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOGS - ARDF Projects - Chaos segmentation\n",
    "\n",
    "This file is a helper for loading the Chaos challenge data\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the dataset\n",
    "\n",
    "The dataset is a Pytorch class. The datasets objects, used along a dataloader provide de data in a pytorch format.\n",
    "The following class, takes numpy arrays for the input data and the targets.\n",
    "\n",
    "*Note:* This class does not operate a data normalization, normalization must be either done before creating the dataset or modify the definition of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Main Class for Image Folder loader.\"\"\"\n",
    "\n",
    "    def __init__(self, data, targets, ids, imsize=None):\n",
    "        \"\"\"Init function.\"\"\"\n",
    "\n",
    "        self.imsize = imsize\n",
    "        self.ids = ids\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        for key, val in data.items():\n",
    "            if key in ids:\n",
    "                self.data.append(val)\n",
    "        for key, val in targets.items():\n",
    "            if key in ids:\n",
    "                self.targets.append(val)\n",
    "\n",
    "        self.coord = []\n",
    "        for d_id, d in enumerate(self.data):\n",
    "            for i in range(d.shape[0]):\n",
    "                self.coord.append([d_id, i])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get item.\"\"\"\n",
    "\n",
    "        i, rid = self.coord[index]\n",
    "        data, target = self.data[i], self.targets[i]\n",
    "        rid = random.randint(0,data.shape[0]-1)\n",
    "        data, target = data[rid], target[rid]\n",
    "\n",
    "\n",
    "        # convert to float32\n",
    "        data = data.astype(np.float32)\n",
    "        target = target.astype(np.float32)\n",
    "\n",
    "        # convert to torch tensors\n",
    "        if len(data.shape)==2:\n",
    "            data = np.expand_dims(data, 0)\n",
    "        else:\n",
    "            # in troch channels are first\n",
    "            data = data.transpose(2,0,1)\n",
    "\n",
    "        if self.imsize is not None:\n",
    "            _, w, h = data.shape\n",
    "            x1 = random.randint(0, w - self.imsize)\n",
    "            y1 = random.randint(0, h - self.imsize)\n",
    "            data = data[:, x1:x1+self.imsize, y1:y1+self.imsize]\n",
    "            target = target[x1:x1+self.imsize, y1:y1+self.imsize]\n",
    "\n",
    "        # convert to torch tensors\n",
    "        data = torch.from_numpy(data)\n",
    "        target = torch.from_numpy(target)\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length.\"\"\"\n",
    "        return len(self.coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "We provide the data in the form of an archive, containing 6 pickle files. You can download them [here](https://drive.google.com/open?id=12HKFKSzK4CXTT3Uaf77l1ld93DlCLVYe).\n",
    "\n",
    "Supposing they are stored on you Google Drive in the ```data/chaos``` folder, you can mount the folder using the following code. Set ```USE_COLAB``` to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_COLAB = False\n",
    "if USE_COLAB:\n",
    "    # mount the goole drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # download cifar on GoogleDrive\n",
    "    data_dir = \"/content/drive/My Drive/data/chaos\"\n",
    "else:\n",
    "    data_dir = \"data/chaos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(os.path.join(data_dir, \"CT_train_data.pkl\"),\"rb\"))\n",
    "gt = pickle.load(open(os.path.join(data_dir, \"CT_train_gt.pkl\"),\"rb\"))\n",
    "\n",
    "# data = pickle.load(open(open(os.path.join(data_dir, \"MR_T1DUAL_train_data.pkl\"),\"rb\"))\n",
    "# gt = pickle.load(open(open(os.path.join(data_dir, \"MR_T1DUAL_train_gt.pkl\"),\"rb\"))\n",
    "\n",
    "# data = pickle.load(open(open(os.path.join(data_dir, \"MR_T2SPIR_train_data.pkl\"),\"rb\"))\n",
    "# gt = pickle.load(open(open(os.path.join(data_dir, \"MR_T2SPIR_train_gt.pkl\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data loader and iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([2, 1, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([1, 1, 256, 256]) torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "dataset = ImageDataset(data, gt, ids=[1,2,3], imsize=256)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for inputs, targets in dataloader:\n",
    "    print(inputs.size(), targets.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
