{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOGS - Neural Networks - Practical Session\n",
    "\n",
    "## Objective\n",
    "\n",
    "The objective of this practical session is dual:\n",
    "* the creation of a simple neural network for classification\n",
    "* implementation or usage of metrics and visualization tools to evaluate the performance of the training\n",
    "\n",
    "It includes the implementation of:\n",
    "* the neural network\n",
    "* the optimization loop\n",
    "* the test and evaluation\n",
    "\n",
    "## Language and libraries\n",
    "\n",
    "The whole programming part will use Python programming. \n",
    "\n",
    "It is a first contact with [Pytorch](https://pytorch.org/), one of the mainly used Deep Learning frameworks (along with TensorFlow).\n",
    "\n",
    "We use it as tensor library. Note that in this session, Numpy should be sufficient to do everything.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and install Pytorch execute ONLY on COLAB\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Deep Learning library\n",
    "import matplotlib.pyplot as plt # Result display library\n",
    "from tqdm import tnrange # library for progress bars\n",
    "from sklearn.metrics import classification_report # Scikit learn metrics for classification\n",
    "from IPython.display import clear_output # command to clear the figures\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "Two functions are given in order to generate data:\n",
    "* ```generate_data(npts)``` which returns a ```npts X 2``` matrix of points with random coordinates in [-1,1]\n",
    "* ```generate_bar_labels(pts)``` which returns a vector of labels with a linear separation\n",
    "\n",
    "<font color='red'>Question 1</font>: Understand the two functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(npts):\n",
    "    pts = torch.rand(npts, 2)*2-1\n",
    "    return pts\n",
    "\n",
    "def generate_bar_labels(pts):\n",
    "    labels = torch.abs(pts)[:,1]>0.4\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "In order to visualize the results (and ensure our generations functions are OK), we create a visualization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pts_labels(pts, labels):\n",
    "    plt.scatter(pts[labels==0][:,0], pts[labels==0][:,1])\n",
    "    plt.scatter(pts[labels==1][:,0], pts[labels==1][:,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question 2</font>: Generate 1000 points and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pts = ...\n",
    "# labels = ...\n",
    "# display..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Visualisation is a good way to evaluate the performance of our algorithm, but still, we need quantitative values to assess the quality of the training.\n",
    "\n",
    "To achieve that, we will use the functions from the Scikit Learn library. This library has already been used in the previous classes. It provides several machine learning algorithm and utility functions for evaluation. The function to be used are ```confusion_matrix``` ([here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)) and ```classification_report``` ([here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)).\n",
    "\n",
    "\n",
    "### The recall\n",
    "\n",
    "For a given class *c*, the recall measures the fraction of correctly classified samples compared to the number of samples that should have been classified *c*.\n",
    "\n",
    "$R = \\frac{Tp}{Tp+Fn}$\n",
    "\n",
    "### The precision\n",
    "\n",
    "For a given class *c*, the precision measures the fraction of correctly classified samples compared to the number of samples that have been predicted *c*.\n",
    "\n",
    "$P = \\frac{Tp}{Tp+Fp}$\n",
    "\n",
    "### F1 Score\n",
    "\n",
    "F1 score is a synthetic score, function of both recall and precision. It lies in $[0,1]$ and is 1 only if both precision and recall are 1:\n",
    "\n",
    "$ F_1 = 2 \\frac{R*P}{R+P}$\n",
    "\n",
    "<font color='red'>Question 3</font>: in the following cell, we generated data and linear labels (the ground truth). We also generated estimated labels (the prediction). Use the documentation from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) to print the classification scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the points and ground truth labels\n",
    "print(\"Grount truth\")\n",
    "# pts = ...\n",
    "# labels = ...\n",
    "# display...\n",
    "\n",
    "# create estimated labels\n",
    "print(\"Prediction\")\n",
    "estimated_labels = (pts[:,0]>0.6).long()\n",
    "# display...\n",
    "\n",
    "# Display the classification scores\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function to be used is the cross-entropy.\n",
    "For a given class label $c$, the cross entropy is defined by:\n",
    "\n",
    "$ L(x,c) = -\\log(\\frac{\\exp(x[c])}{\\sum_i \\exp(x[i])}) = -x[c] + \\log(\\sum_i \\exp(x[i]))$\n",
    "\n",
    "The derivative is then given by:\n",
    "\n",
    "$ \\frac{\\partial{d} L}{\\partial x_i} = \\frac{\\exp x[i])}{\\sum_j \\exp(x[j])}$ if $i \\neq c$\n",
    "\n",
    "and $ \\frac{\\partial{d} L}{\\partial x_i} = \\frac{\\exp x[i])}{\\sum_j \\exp(x[j])} - 1$ if $i = c$\n",
    "\n",
    "<font color='red'>Question 4</font>: complete the function prototypes for the loss and its derivative. Note that the output of ```cross_entropy``` is a real and the output of ```d_cross_entropy``` is a vector.\n",
    "\n",
    "For verification purpose, the following commands:\n",
    "\n",
    "\n",
    "```\n",
    "print(cross_entropy(torch.FloatTensor([-2,0.8]), 1))\n",
    "print(d_cross_entropy(torch.FloatTensor([-2,0.8]), 1))\n",
    "```\n",
    "\n",
    "should give these values:\n",
    "\n",
    "```\n",
    "tensor(0.0590)\n",
    "tensor([ 0.0573, -0.0573])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy function\n",
    "def cross_entropy(x,target_label):\n",
    "    pass\n",
    "\n",
    "# derivativ for cross entropy function\n",
    "def d_cross_entropy(x, label):\n",
    "    pass\n",
    "\n",
    "# Validation of the functions\n",
    "print(cross_entropy(torch.FloatTensor([-2,0.8]), 1))\n",
    "print(d_cross_entropy(torch.FloatTensor([-2,0.8]), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function\n",
    "\n",
    "The sigmoid is our activation function:\n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1+\\exp{-x}}$\n",
    "\n",
    "And its derivative:\n",
    "\n",
    "$\\frac{d \\sigma(x)}{d x} = \\sigma(x) * (1-\\sigma(x))$\n",
    "\n",
    "<font color='red'>Question 5</font>: complete the function prototypes for the sigmoid and its derivative. Note that the output dimension is the same as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    pass\n",
    "\n",
    "# derivative of the sigmoid function\n",
    "def d_sigmoid(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network design and optimization\n",
    "\n",
    "We have now everything that we need to build and actual neural network.\n",
    "Our network will be a simple Multi Layer Perceptron with two layers of neurons separated by a sigmoid.\n",
    "The loss will be a cross entropy.\n",
    "\n",
    "The neural layer formula is given by:\n",
    "\n",
    "$ y = W*x + b$\n",
    "\n",
    "<font color='red'>Question 6</font>: create the $W1, b1, W2, b2$, the matrices of parameters for the layers.\n",
    "Use the function ```torch.rand(dim1, dim2, ...)``` to create random tensors. ```torch.rand(dim1, dim2, ...)``` produce values in $[0,1]$, apply a transformation to the tensors to produce values in $[-1,1]$\n",
    "\n",
    "<font color='red'>Question 7</font>: create a training set (data and labels) of size 1000.\n",
    "\n",
    "<font color='red'>Question 8</font>: create a test set (data and labels) of size 1000.\n",
    "\n",
    "We know iterate 10 times over the training set (10 epochs).\n",
    "At each epoch the whole training set is seen by the network.\n",
    "\n",
    "<font color='red'>Question 9</font>: compute the forward pass.\n",
    "\n",
    "<font color='red'>Question 10</font>: compute the loss (error) using the cross entropy function.\n",
    "\n",
    "<font color='red'>Question 11</font>: compute the derivative of the corss entropy and the paramters using the previously creatd funciton and the chain rule.\n",
    "\n",
    "<font color='red'>Question 12</font>: update the weights with learning rate 0.01.\n",
    "\n",
    "<font color='red'>Question 13</font>: compute the forward pass for the test set.\n",
    "\n",
    "<font color='red'>Question 14</font>: display the testing set with the true labels and the predictions. Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6: create the paramter tensors\n",
    "# W1 =...\n",
    "# b1 = ...\n",
    "# W2,b2...\n",
    "\n",
    "# Question 7: Training set\n",
    "# pts, labels...\n",
    "\n",
    "# Question 8: Testing set\n",
    "# pts_test, labels_test...\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-2\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i in tnrange(pts.size(0)):\n",
    "\n",
    "        # Question 9: forward pass\n",
    "        # y1 = ...\n",
    "        # y1_s = ...\n",
    "        # y2 = ...\n",
    "        \n",
    "        # Question 10: loss\n",
    "        # error = ...\n",
    "        \n",
    "        \n",
    "        # Question 11: derivative\n",
    "        \n",
    "        # error\n",
    "        # dy2 = ...\n",
    "        \n",
    "        # layer 2\n",
    "        # dW2 = ...\n",
    "        # db2 = ...\n",
    "        # dy1_s = ...\n",
    "        \n",
    "        # sigmoid\n",
    "        # dy1 = ...\n",
    "\n",
    "        # layer 1\n",
    "        # dW1 = ...\n",
    "        # db1 = ...\n",
    "\n",
    "        \n",
    "        # Question 12: Update the weights\n",
    "        # W2 = ...\n",
    "        # b2, W1, b1...\n",
    "        \n",
    "        total_loss += error\n",
    "        \n",
    "    \n",
    "    labels_prediction = torch.zeros(pts_test.size(0))\n",
    "    for i in range(pts_test.size(0)):\n",
    "\n",
    "        # Question 13: forward pass for test data\n",
    "        # ...\n",
    "        \n",
    "        if y2[0] < y2[1]:\n",
    "            labels_prediction[i] = 1\n",
    "\n",
    "            \n",
    "    clear_output() # remove all display output\n",
    "    print(\"Epoch \", epoch)\n",
    "    print(\"Loss\", total_loss/(pts.size(0)))\n",
    "    \n",
    "    # Question 14: display the results\n",
    "    # classification results\n",
    "    # display points\n",
    "    \n",
    "    sleep(2) # sleep for 2 seconds (only to have time to visualize the results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Using Pytorch functions\n",
    "\n",
    "In the previous part, we did not used any function specific to PyTorch. We used it as a tensor library similar to NumPy.\n",
    "\n",
    "We now go a step forward in the use of the library.\n",
    "We will see how to create a network with predefined layer and use the automatic differenciation to avoid computing the gradient by hand.\n",
    "\n",
    "First we will work on a more difficult example than before.\n",
    "\n",
    "<font color='red'>Question 15</font>: Create more difficult classification task. Here we want create donut (label 1 for x in [-0.4, 0.4], a disk centered around 0, ...). Display a generated set for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 15\n",
    "def generate_donut_labels(pts):\n",
    "    pass\n",
    "\n",
    "# pts = ...\n",
    "# labels = ...\n",
    "# display..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definition\n",
    "\n",
    "The networks are Python Classes that inherit from the ```torch.nn.Module``` class.\n",
    "It is usually composed of two functions: ```__init__``` (the initializer) and ```forward``` that define the forward pass.\n",
    "\n",
    "Here is an example of network with a single neural layer without non-linerarity.\n",
    "The input size is 2 and the output is 16.\n",
    "\n",
    "```\n",
    "class NetworkExample(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkExample, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(2,16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.l1(x)\n",
    "        return y\n",
    "```\n",
    "\n",
    "<font color='red'>Question 16</font>: Create a network class with 3 layers separated with ReLUs.\n",
    "Use the function ```torch.nn.functional.relu```. The hidden size will be 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question 17</font>: Create training set (size 5000) and testing set (size 1000).\n",
    "\n",
    "The next step is to create the network, this is simply done by creating an instance of the class previously defined.\n",
    "\n",
    "Then, we create an **optimizer**, it is convenience class that contains the update policy for the weights of the network.\n",
    "Here, we use **Stochastic Gradient Descent**, the optimizer class ```torch.optim.SGD```.\n",
    "The first argument is the parameters of the networks (accessible by ```net.parameters()```), the second is the learning rate. There is an optional argument, the momentum, default value is 0.\n",
    "\n",
    "The operation is then similar to the previous code.\n",
    "We train for 10 epochs.\n",
    "Main differences from before:\n",
    "\n",
    "* pytorch use mini batches (several points are evaluated at the same time), so the input have a size of $(N \\times D)$ where $N$ is the number of points and $D$ the dimension (2 in our case). We stick to train with one point, but we still need to resize the input to $(1,2)$. For that use the method ```x.unsqueeze(0)``` which add a dimension at position 0.\n",
    "\n",
    "* the loss function is ```torch.nn.functional.cross_entropy(prediction, target)```\n",
    "\n",
    "* before computiong the gradients, gradient storage must be put to zero with ```optimizer.zero_grad()```.\n",
    "\n",
    "* the gradients are computed by using the ```backward()``` method on the loss tensor.\n",
    "\n",
    "* the weight update is done with ```optimizer.step()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 17: Training and testing set\n",
    "# ...\n",
    "\n",
    "# network creation\n",
    "net = Network()\n",
    "\n",
    "# optimizer creation\n",
    "lr = 1e-2\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    net.train()\n",
    "    t = tnrange(pts.size(0))\n",
    "    total_loss = 0\n",
    "    for i in t:\n",
    "        \n",
    "\n",
    "        # create the input / target tensors\n",
    "        # ...\n",
    "        \n",
    "        # forward and error\n",
    "        \n",
    "        # optimizer zero grad, bacward computation and weight update\n",
    "        \n",
    "        total_loss += error.item()\n",
    "        t.set_postfix(Loss=total_loss/(i+1))\n",
    "\n",
    "    # predict all test at one time\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        labels_prediction = net(pts_test)\n",
    "        labels_prediction = torch.argmax(labels_prediction, dim=1)\n",
    "\n",
    "    clear_output()\n",
    "    print(\"Epoch \", epoch)\n",
    "    # display results\n",
    "    # ...\n",
    "    sleep(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question 18</font>: add momentum to the optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
